{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metal_data_loader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eileenblum/Lyric-Generator/blob/main/Metal_data_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_P8He5OkG7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "780f67c3-28c3-46ef-8719-12cd8039cc3d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import string\n",
        "import nltk\n",
        "import gensim\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "!pip install word2vec\n",
        "import word2vec\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import abc\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "from gensim.models import Word2Vec\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "\n",
        "##########################  1  #################################################\n",
        "############# Loading the data #################################################\n",
        "################################################################################\n",
        "#establish working directory:\n",
        "os.chdir(r'/content/drive/MyDrive/metal_lyrics')\n",
        "os.getcwd()\n",
        "entries = os.scandir(r'/content/drive/MyDrive/metal_lyrics')\n",
        "entries\n",
        "\n",
        "###############  Gather the Metal Files  ################################\n",
        "#Make sure to change this path to where YOU are storing lyrics in your computer    \n",
        "Metal_name_and_text = {}\n",
        "count = 0\n",
        "# Walking a directory tree and printing the names of the directories and files\n",
        "for dirpath, dirnames, files in os.walk(r'/content/drive/MyDrive/metal_lyrics'):\n",
        "    #print(f'Found directory: {dirpath}')\n",
        "    for file_name in files:\n",
        "        count = count + 1\n",
        "        os.listdir()\n",
        "        if count%1000 == 0:\n",
        "          print(count)\n",
        "        #print(\"song:\", file_name)\n",
        "        with open(dirpath + r'/' + file_name, \"r\", errors='ignore') as target_file:\n",
        "            Metal_name_and_text[file_name] = target_file.read()\n",
        "\n",
        "Metal_data = (pd.DataFrame.from_dict(Metal_name_and_text, orient='index')).reset_index().rename(index=str, columns={'index': 'song_name', 0: 'lyrics'})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: word2vec in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from word2vec) (1.19.5)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M2X1VXiyrUB"
      },
      "source": [
        "# Getting rid of two non-song files at the beginning (lml_archive.txt and .DS_Store,\n",
        "# and metal_lyrics.iml, modules.xml, workspace.xml, and profile_settings.xml at the end):\n",
        "\n",
        "Metal_data = Metal_data[2:-4]\n",
        "Metal_data.reset_index(inplace=True, drop=True)\n",
        "Metal_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q27z_9bh1BBU"
      },
      "source": [
        "# Adding \"type\" and getting rid of instrumentals.\n",
        "\n",
        "Type = np.ones(shape=(len(Metal_data),1 ))\n",
        "Metal_data['type'] = Type\n",
        "\n",
        "for i in Metal_data.index:\n",
        "  if (Metal_data.loc[i,\"lyrics\"] == \"instrumental\") or (Metal_data.loc[i,\"lyrics\"] == \"\"):\n",
        "    Metal_data.drop(i,inplace=True)\n",
        "\n",
        "Metal_data.reindex(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhrrhV7hyngD"
      },
      "source": [
        "##########################  2  #################################################\n",
        "############# Preprocessing the Data ###########################################\n",
        "################################################################################\n",
        "\n",
        "Lyrics = Metal_data.copy()\n",
        "\n",
        "Lyrics = Lyrics.dropna()\n",
        "\n",
        "################# Cleaning ##############################\n",
        "stop = stopwords.words('english') #importing ENglish stop words\n",
        "#cleaning and lemmatizing Lyrics:\n",
        "Pro_Lyrics = Lyrics.copy()\n",
        "Pro_Lyrics['lyrics'] = Pro_Lyrics['lyrics'].apply(lambda x: ' '.join(x for x in x.split() if x not in string.punctuation))#All the rows of the text in the data frame is checked for string punctuations, and these are filtered\n",
        "Pro_Lyrics['lyrics'] = Pro_Lyrics['lyrics'].str.replace('[^\\w\\s]','')#REmoves dots using regular expressions\n",
        "Pro_Lyrics['lyrics'] = Pro_Lyrics['lyrics'].apply(lambda x:' '.join(x.lower() for x in x.split())) #Converting text to lower case\n",
        "Pro_Lyrics['lyrics'] = Pro_Lyrics['lyrics'].apply(lambda x: ' '.join(x for x in x.split() if  not x.isdigit()))#Digits are removed from the text\n",
        "Pro_Lyrics['lyrics'] = Pro_Lyrics['lyrics'].apply(lambda x: ' '.join(x for x in x.split() if not x in stop))#Stop words are removed at this stage\n",
        "Pro_Lyrics['lyrics'] = Pro_Lyrics['lyrics'].apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split()]))#Words are filtered now, and different form of the same word is removed using lemmatization\n",
        "\n",
        "Pro_Lyrics_list = []\n",
        "for i in Pro_Lyrics['lyrics']:\n",
        "     li = list(i.split(\" \"))\n",
        "     Pro_Lyrics_list.append(li)\t\n",
        "     \n",
        "Pro_Lyrics['words'] = Pro_Lyrics_list #Adding the list of words/lemmas used for every song     \n",
        "\n",
        "################################################################################\n",
        "#######  END OF PREPROCESSING  #################################################\n",
        "################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhG_GdJ32oCG"
      },
      "source": [
        "for i in Pro_Lyrics.index:\n",
        "  if (Pro_Lyrics.loc[i,\"lyrics\"] == \"instrumental\") or (Pro_Lyrics.loc[i,\"lyrics\"] == \"\"):\n",
        "    Pro_Lyrics.drop(i,inplace=True)\n",
        "\n",
        "Pro_Lyrics.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "2YT6KsGN6UIO",
        "outputId": "aec491e3-bc0d-4980-ef6f-c3f1dbe4a051"
      },
      "source": [
        "Pro_Lyrics.sample(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level_0</th>\n",
              "      <th>index</th>\n",
              "      <th>song_name</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>type</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10610</th>\n",
              "      <td>10610</td>\n",
              "      <td>11806</td>\n",
              "      <td>7. Loving You.txt</td>\n",
              "      <td>verse confused knowing used blinded headed hel...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[verse, confused, knowing, used, blinded, head...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15015</th>\n",
              "      <td>15015</td>\n",
              "      <td>16611</td>\n",
              "      <td>4. I ve Waited.txt</td>\n",
              "      <td>waited long alone somehow knew would find woul...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[waited, long, alone, somehow, knew, would, fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13370</th>\n",
              "      <td>13370</td>\n",
              "      <td>14790</td>\n",
              "      <td>2. Svarta Pisten.txt</td>\n",
              "      <td>snãkanoner har talat pisten ligger blank som e...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[snãkanoner, har, talat, pisten, ligger, blank...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48103</th>\n",
              "      <td>48103</td>\n",
              "      <td>53117</td>\n",
              "      <td>1. Metal Health.txt</td>\n",
              "      <td>well im axe grinder piledriver mother say neve...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[well, im, axe, grinder, piledriver, mother, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24063</th>\n",
              "      <td>24063</td>\n",
              "      <td>26562</td>\n",
              "      <td>4. Enfermo Poder.txt</td>\n",
              "      <td>derramando enfermedad infectando con guerras m...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[derramando, enfermedad, infectando, con, guer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>10012</td>\n",
              "      <td>11165</td>\n",
              "      <td>14. A Dead Current.txt</td>\n",
              "      <td>hot topic edition track light heaven burning s...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[hot, topic, edition, track, light, heaven, bu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36343</th>\n",
              "      <td>36343</td>\n",
              "      <td>40164</td>\n",
              "      <td>2. Crawl Back.txt</td>\n",
              "      <td>known scream known today relayed thought tranq...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[known, scream, known, today, relayed, thought...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49592</th>\n",
              "      <td>49592</td>\n",
              "      <td>54721</td>\n",
              "      <td>15. Leaving Traces.txt</td>\n",
              "      <td>one look last second stay forever beautiful th...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[one, look, last, second, stay, forever, beaut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13869</th>\n",
              "      <td>13869</td>\n",
              "      <td>15355</td>\n",
              "      <td>4. Jesse James.txt</td>\n",
              "      <td>nation set fire war lost month spent bushwhack...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[nation, set, fire, war, lost, month, spent, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52116</th>\n",
              "      <td>52116</td>\n",
              "      <td>57542</td>\n",
              "      <td>4. Nightmare Logic.txt</td>\n",
              "      <td>slumber reason give birth demon new battle tak...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[slumber, reason, give, birth, demon, new, bat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2834</th>\n",
              "      <td>2834</td>\n",
              "      <td>3161</td>\n",
              "      <td>9. Tell Me Why.txt</td>\n",
              "      <td>eye see thing real wicked smile implies believ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[eye, see, thing, real, wicked, smile, implies...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18595</th>\n",
              "      <td>18595</td>\n",
              "      <td>20521</td>\n",
              "      <td>3. Motion Sickness.txt</td>\n",
              "      <td>take aim treacherous water come feeling panic ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[take, aim, treacherous, water, come, feeling,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63511</th>\n",
              "      <td>63511</td>\n",
              "      <td>70143</td>\n",
              "      <td>19. The World That You Made.txt</td>\n",
              "      <td>music lyric jakobson youve climbed stair made ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[music, lyric, jakobson, youve, climbed, stair...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48382</th>\n",
              "      <td>48382</td>\n",
              "      <td>53407</td>\n",
              "      <td>3. Hellfire.txt</td>\n",
              "      <td>wilton la torre lock make madness itâs world g...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[wilton, la, torre, lock, make, madness, itâs,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3565</th>\n",
              "      <td>3565</td>\n",
              "      <td>3960</td>\n",
              "      <td>1. The Shepherd.txt</td>\n",
              "      <td>part come live love pleasure prove hill valley...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[part, come, live, love, pleasure, prove, hill...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       level_0  index  ... type                                              words\n",
              "10610    10610  11806  ...  1.0  [verse, confused, knowing, used, blinded, head...\n",
              "15015    15015  16611  ...  1.0  [waited, long, alone, somehow, knew, would, fi...\n",
              "13370    13370  14790  ...  1.0  [snãkanoner, har, talat, pisten, ligger, blank...\n",
              "48103    48103  53117  ...  1.0  [well, im, axe, grinder, piledriver, mother, s...\n",
              "24063    24063  26562  ...  1.0  [derramando, enfermedad, infectando, con, guer...\n",
              "10012    10012  11165  ...  1.0  [hot, topic, edition, track, light, heaven, bu...\n",
              "36343    36343  40164  ...  1.0  [known, scream, known, today, relayed, thought...\n",
              "49592    49592  54721  ...  1.0  [one, look, last, second, stay, forever, beaut...\n",
              "13869    13869  15355  ...  1.0  [nation, set, fire, war, lost, month, spent, b...\n",
              "52116    52116  57542  ...  1.0  [slumber, reason, give, birth, demon, new, bat...\n",
              "2834      2834   3161  ...  1.0  [eye, see, thing, real, wicked, smile, implies...\n",
              "18595    18595  20521  ...  1.0  [take, aim, treacherous, water, come, feeling,...\n",
              "63511    63511  70143  ...  1.0  [music, lyric, jakobson, youve, climbed, stair...\n",
              "48382    48382  53407  ...  1.0  [wilton, la, torre, lock, make, madness, itâs,...\n",
              "3565      3565   3960  ...  1.0  [part, come, live, love, pleasure, prove, hill...\n",
              "\n",
              "[15 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp6Lrbz-Lkgx"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/NLP bootcamp project/Pro Lyrics list.txt\", \"wb\") as fp:\n",
        "  pickle.dump(Pro_Lyrics_list, fp)\n",
        "\n",
        "Pro_Lyrics.to_csv(\"/content/drive/MyDrive/NLP bootcamp project/Pro_Lyrics_df.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnUPn9k_x-Tw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}