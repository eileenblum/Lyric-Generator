{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metal_data_loader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eileenblum/Lyric-Generator/blob/main/Metal_data_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_P8He5OkG7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207e0cfb-589d-4c35-d7bb-7fcf01df7502"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import string\n",
        "import nltk\n",
        "import gensim\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import abc\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "from gensim.models import Word2Vec\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "\n",
        "##########################  1  #################################################\n",
        "############# Loading the data #################################################\n",
        "################################################################################\n",
        "#establish working directory:\n",
        "os.chdir(r'/content/drive/MyDrive/metal_lyrics')\n",
        "os.getcwd()\n",
        "entries = os.scandir(r'/content/drive/MyDrive/metal_lyrics')\n",
        "entries\n",
        "\n",
        "###############  Gather the Metal Files  ################################\n",
        "#Make sure to change this path to where YOU are storing lyrics in your computer    \n",
        "Metal_name_and_text = {}\n",
        "count = 0\n",
        "# Walking a directory tree and printing the names of the directories and files\n",
        "for dirpath, dirnames, files in os.walk(r'/content/drive/MyDrive/metal_lyrics'):\n",
        "    #print(f'Found directory: {dirpath}')\n",
        "    for file_name in files:\n",
        "        count = count + 1\n",
        "        os.listdir()\n",
        "        if count%1000 == 0:\n",
        "          print(count)\n",
        "        #print(\"song:\", file_name)\n",
        "        with open(dirpath + r'/' + file_name, \"r\", errors='ignore') as target_file:\n",
        "            Metal_name_and_text[file_name] = target_file.read()\n",
        "\n",
        "Metal_data = (pd.DataFrame.from_dict(Metal_name_and_text, orient='index')).reset_index().rename(index=str, columns={'index': 'song_name', 0: 'lyrics'})\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M2X1VXiyrUB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8ae7cdc6-7204-4fe1-f06e-73cce17025bd"
      },
      "source": [
        "# Getting rid of two non-song files at the beginning (lml_archive.txt and .DS_Store,\n",
        "# and metal_lyrics.iml, modules.xml, workspace.xml, and profile_settings.xml at the end):\n",
        "\n",
        "Metal_data = Metal_data[2:-4]\n",
        "Metal_data.reset_index(inplace=True, drop=True)\n",
        "Metal_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_name</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. The Moulting (Intro).txt</td>\n",
              "      <td>\"Throughout the fluid mass, but downward purge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3. Feed Them Hate.txt</td>\n",
              "      <td>What lies above nourishes the below. The waste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2. Vehement Indulgences.txt</td>\n",
              "      <td>Sickening lives. Throes of squalor. Hollowed l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4. The Bottomless Perdition.txt</td>\n",
              "      <td>Womb of nature.\\nSpoil and ruin.\\nDeath yawn s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3. Valley Of Defilement.txt</td>\n",
              "      <td>Rotten throne.\\nCorrupted master.\\nSending the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         song_name                                             lyrics\n",
              "0      1. The Moulting (Intro).txt  \"Throughout the fluid mass, but downward purge...\n",
              "1            3. Feed Them Hate.txt  What lies above nourishes the below. The waste...\n",
              "2      2. Vehement Indulgences.txt  Sickening lives. Throes of squalor. Hollowed l...\n",
              "3  4. The Bottomless Perdition.txt  Womb of nature.\\nSpoil and ruin.\\nDeath yawn s...\n",
              "4      3. Valley Of Defilement.txt  Rotten throne.\\nCorrupted master.\\nSending the..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q27z_9bh1BBU"
      },
      "source": [
        "# Adding \"type\" and getting rid of instrumentals.\n",
        "\n",
        "Type = np.ones(shape=(len(Metal_data),1 ))\n",
        "Metal_data['type'] = Type\n",
        "\n",
        "for i in Metal_data.index:\n",
        "  if (Metal_data.loc[i,\"lyrics\"] == \"instrumental\") or (Metal_data.loc[i,\"lyrics\"] == \"\"):\n",
        "    Metal_data.drop(i,inplace=True)\n",
        "\n",
        "Metal_data.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RMQtlbuip7AF",
        "outputId": "9e990121-e3ff-42b0-c704-4a1a10a3f900"
      },
      "source": [
        "Metal_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_name</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. The Moulting (Intro).txt</td>\n",
              "      <td>\"Throughout the fluid mass, but downward purge...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3. Feed Them Hate.txt</td>\n",
              "      <td>What lies above nourishes the below. The waste...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2. Vehement Indulgences.txt</td>\n",
              "      <td>Sickening lives. Throes of squalor. Hollowed l...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4. The Bottomless Perdition.txt</td>\n",
              "      <td>Womb of nature.\\nSpoil and ruin.\\nDeath yawn s...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3. Valley Of Defilement.txt</td>\n",
              "      <td>Rotten throne.\\nCorrupted master.\\nSending the...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         song_name  ... type\n",
              "0      1. The Moulting (Intro).txt  ...  1.0\n",
              "1            3. Feed Them Hate.txt  ...  1.0\n",
              "2      2. Vehement Indulgences.txt  ...  1.0\n",
              "3  4. The Bottomless Perdition.txt  ...  1.0\n",
              "4      3. Valley Of Defilement.txt  ...  1.0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI58ZO0W4mtR"
      },
      "source": [
        "def cleaner_keep_newlines(df):\n",
        "  df_copy = df.copy()\n",
        "  df_copy['cleaned_lyrics'] = df_copy['lyrics'].apply(lambda x: ' '.join(x for x in x.split(\" \") if x not in string.punctuation))#All the rows of the text in the data frame is checked for string punctuations, and these are filtered\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].str.replace(r'[^\\w\\s\\n\\r\\t]','')#REmoves dots using regular expressions\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x:' '.join(x.lower() for x in x.split(\" \"))) #Converting text to lower case\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x: ' '.join(x for x in x.split(\" \") if  not x.isdigit()))#Digits are removed from the text\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x: ' '.join(x for x in x.split(\" \") if not x in stop))#Stop words are removed at this stage\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split(\" \")]))#Words are filtered now, and different form of the same word is removed using lemmatization\n",
        "\n",
        "  return df_copy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNkEf5k35FeD"
      },
      "source": [
        "def cleaner(df):\n",
        "  df_copy = df.copy()\n",
        "  df_copy['cleaned_lyrics'] = df_copy['lyrics'].apply(lambda x: ' '.join(x for x in x.split() if x not in string.punctuation))#All the rows of the text in the data frame is checked for string punctuations, and these are filtered\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].str.replace(r'[^\\w\\s]','')#REmoves dots using regular expressions\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x:' '.join(x.lower() for x in x.split())) #Converting text to lower case\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x: ' '.join(x for x in x.split() if  not x.isdigit()))#Digits are removed from the text\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x: ' '.join(x for x in x.split() if not x in stop))#Stop words are removed at this stage\n",
        "  df_copy['cleaned_lyrics'] = df_copy['cleaned_lyrics'].apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split()]))#Words are filtered now, and different form of the same word is removed using lemmatization\n",
        "\n",
        "  return df_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhrrhV7hyngD"
      },
      "source": [
        "##########################  2  #################################################\n",
        "############# Preprocessing the Data ###########################################\n",
        "################################################################################\n",
        "import re\n",
        "\n",
        "Lyrics = Metal_data.copy()\n",
        "\n",
        "Lyrics = Lyrics.dropna()\n",
        "\n",
        "################# Cleaning ##############################\n",
        "stop = stopwords.words('english') #importing ENglish stop words\n",
        "#cleaning and lemmatizing Lyrics:\n",
        "Pro_Lyrics = cleaner_keep_newlines(Lyrics)\n",
        "Pro_Lyrics_no_newlines = cleaner(Lyrics)\n",
        "\n",
        "# Here we compile a list of words, with no newline characters\n",
        "# (This no-newline-df won't be used again, as we need the newline\n",
        "# characters for splitting-by-line in the data processing.)\n",
        "Pro_Lyrics_list = []\n",
        "for i in Pro_Lyrics_no_newlines['cleaned_lyrics']:\n",
        "     li = list(i.split(\" \"))\n",
        "     Pro_Lyrics_list.append(li)\t\n",
        "     \n",
        "Pro_Lyrics['words'] = Pro_Lyrics_list #Adding the list of words/lemmas used for every song     \n",
        "\n",
        "################################################################################\n",
        "#######  END OF PREPROCESSING  #################################################\n",
        "################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhG_GdJ32oCG"
      },
      "source": [
        "for i in Pro_Lyrics.index:\n",
        "  if (Pro_Lyrics.loc[i,\"cleaned_lyrics\"].replace(r'^[\\w]','') == \"instrumental\") or (Pro_Lyrics.loc[i,\"cleaned_lyrics\"].replace(r'^[\\w]','') == \"\"):\n",
        "    Pro_Lyrics.drop(i,inplace=True)\n",
        "  if (Pro_Lyrics.loc[i,\"cleaned_lyrics\"].replace('\\n','') == \"instrumental\") or (Pro_Lyrics.loc[i,\"cleaned_lyrics\"].replace('\\n','') == \"\"):\n",
        "    Pro_Lyrics.drop(i,inplace=True)\n",
        "    \n",
        "Pro_Lyrics.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "2YT6KsGN6UIO",
        "outputId": "aaabfb97-cd3f-4754-8b1a-ef75f27c6621"
      },
      "source": [
        "Pro_Lyrics.sample(15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>song_name</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>type</th>\n",
              "      <th>cleaned_lyrics</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8920</th>\n",
              "      <td>8. Wasted Life.txt</td>\n",
              "      <td>I wish I could dream without fear and\\nNot to ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>wish could dream without fear and\\nnot live ru...</td>\n",
              "      <td>[wish, could, dream, without, fear, live, rule...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43317</th>\n",
              "      <td>4. Haz Tu Jugada.txt</td>\n",
              "      <td>[Walter Giardino]\\n\\nDebes mostrar tu realidad...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>walter giardino\\n\\ndebes mostrar tu realidad\\n...</td>\n",
              "      <td>[walter, giardino, debes, mostrar, tu, realida...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24300</th>\n",
              "      <td>8. Faceless Queen.txt</td>\n",
              "      <td>\"The face of Tiamat, like the ocean's surface,...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>face tiamat like ocean surface reflection ever...</td>\n",
              "      <td>[face, tiamat, like, ocean, surface, reflectio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23302</th>\n",
              "      <td>7. Credence Of Fort William.txt</td>\n",
              "      <td>[Severe Dementia - Epitaph Of Plassey]\\n\\nNawa...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>severe dementia epitaph plassey\\n\\nnawab thron...</td>\n",
              "      <td>[severe, dementia, epitaph, plassey, nawab, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16808</th>\n",
              "      <td>6. Warlike Conspiracy.txt</td>\n",
              "      <td>My vacant art just imitate\\nA vacant nameless ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>vacant art imitate\\na vacant nameless life\\nth...</td>\n",
              "      <td>[vacant, art, imitate, vacant, nameless, life,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55667</th>\n",
              "      <td>4. Reign Of The Ravenous.txt</td>\n",
              "      <td>This is the sign for those\\nWaiting, all seein...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>sign those\\nwaiting seeing\\nwith wing spread w...</td>\n",
              "      <td>[sign, waiting, seeing, wing, spread, wide, as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10299</th>\n",
              "      <td>8. You Run.txt</td>\n",
              "      <td>Heavy thoughts seem to slip away\\nWhen you wer...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>heavy thought seem slip away\\nwhen darkest day...</td>\n",
              "      <td>[heavy, thought, seem, slip, away, darkest, da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9948</th>\n",
              "      <td>8. Tomes Of Acrimony.txt</td>\n",
              "      <td>Etched within the centuries, \\nbequeathed upon...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>etched within century \\nbequeathed upon genera...</td>\n",
              "      <td>[etched, within, century, bequeathed, upon, ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46918</th>\n",
              "      <td>2. Leatherhead.txt</td>\n",
              "      <td>[Kaufmann, Dirkschneider]\\n\\nJust Give Me A Re...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>kaufmann dirkschneider\\n\\njust give reason\\nan...</td>\n",
              "      <td>[kaufmann, dirkschneider, give, reason, iâll, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6891</th>\n",
              "      <td>10. Fag Basher.txt</td>\n",
              "      <td>Don't look back at your wasted like us don't e...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>dont look back wasted like u dont even try vis...</td>\n",
              "      <td>[dont, look, back, wasted, like, u, dont, even...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35529</th>\n",
              "      <td>2. Call of the Raven.txt</td>\n",
              "      <td>The Sun awakes and shines on thee\\nEnlightenin...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>sun awakes shine thee\\nenlightening blackened ...</td>\n",
              "      <td>[sun, awakes, shine, thee, enlightening, black...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16421</th>\n",
              "      <td>8. The Other s Fall.txt</td>\n",
              "      <td>Meeting eye to eye so disparate\\nAll unrecogni...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>meeting eye eye disparate\\nall unrecognized co...</td>\n",
              "      <td>[meeting, eye, eye, disparate, unrecognized, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23523</th>\n",
              "      <td>1. Metal Asylum.txt</td>\n",
              "      <td>Judas Priest, The Maiden Band\\nBrought us to t...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>juda priest maiden band\\nbrought u promised la...</td>\n",
              "      <td>[juda, priest, maiden, band, brought, u, promi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53331</th>\n",
              "      <td>1. One Step Into Paradise (2000 version).txt</td>\n",
              "      <td>It's the night I'll be with you \\nLovely to se...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>night ill \\nlovely see lovely hear \\nyoure tva...</td>\n",
              "      <td>[night, ill, lovely, see, lovely, hear, youre,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61137</th>\n",
              "      <td>9. Seed Awakening.txt</td>\n",
              "      <td>There is no stronger drug than reality\\nTwist ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>stronger drug reality\\ntwist change time nothi...</td>\n",
              "      <td>[stronger, drug, reality, twist, change, time,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          song_name  ...                                              words\n",
              "8920                             8. Wasted Life.txt  ...  [wish, could, dream, without, fear, live, rule...\n",
              "43317                          4. Haz Tu Jugada.txt  ...  [walter, giardino, debes, mostrar, tu, realida...\n",
              "24300                         8. Faceless Queen.txt  ...  [face, tiamat, like, ocean, surface, reflectio...\n",
              "23302               7. Credence Of Fort William.txt  ...  [severe, dementia, epitaph, plassey, nawab, th...\n",
              "16808                     6. Warlike Conspiracy.txt  ...  [vacant, art, imitate, vacant, nameless, life,...\n",
              "55667                  4. Reign Of The Ravenous.txt  ...  [sign, waiting, seeing, wing, spread, wide, as...\n",
              "10299                                8. You Run.txt  ...  [heavy, thought, seem, slip, away, darkest, da...\n",
              "9948                       8. Tomes Of Acrimony.txt  ...  [etched, within, century, bequeathed, upon, ge...\n",
              "46918                            2. Leatherhead.txt  ...  [kaufmann, dirkschneider, give, reason, iâll, ...\n",
              "6891                             10. Fag Basher.txt  ...  [dont, look, back, wasted, like, u, dont, even...\n",
              "35529                      2. Call of the Raven.txt  ...  [sun, awakes, shine, thee, enlightening, black...\n",
              "16421                       8. The Other s Fall.txt  ...  [meeting, eye, eye, disparate, unrecognized, c...\n",
              "23523                           1. Metal Asylum.txt  ...  [juda, priest, maiden, band, brought, u, promi...\n",
              "53331  1. One Step Into Paradise (2000 version).txt  ...  [night, ill, lovely, see, lovely, hear, youre,...\n",
              "61137                         9. Seed Awakening.txt  ...  [stronger, drug, reality, twist, change, time,...\n",
              "\n",
              "[15 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNp3UU7sr5hG"
      },
      "source": [
        "Pro_Lyrics_corpus = []\n",
        "\n",
        "for L in Pro_Lyrics_list:\n",
        "  for word in L:\n",
        "    if word not in Pro_Lyrics_corpus:\n",
        "      Pro_Lyrics_corpus.append(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp6Lrbz-Lkgx"
      },
      "source": [
        "import pickle\n",
        "\n",
        "# saving corpus:\n",
        "with open(\"/content/drive/MyDrive/NLP bootcamp project/Pro_Lyrics_corpus.txt\", \"wb\") as fp:\n",
        "  pickle.dump(Pro_Lyrics_corpus, fp)\n",
        "\n",
        "# saving word list (contains repeats):\n",
        "with open(\"/content/drive/MyDrive/NLP bootcamp project/Pro Lyrics list.txt\", \"wb\") as fp:\n",
        "  pickle.dump(Pro_Lyrics_list, fp)\n",
        "\n",
        "# saving dataframe:\n",
        "Pro_Lyrics.to_csv(\"/content/drive/MyDrive/NLP bootcamp project/Pro_Lyrics_df.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHVZyOrGSV7N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}